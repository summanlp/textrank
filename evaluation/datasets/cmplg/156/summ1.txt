
This paper investigates model merging, a technique for deriving Markov
models from text or speech corpora. Models are derived by starting with
a large and specific model and by successively combining states to build
smaller and more general models. We present methods to reduce the time
complexity of the algorithm and report on experiments on deriving
language models for a speech recognition task. The experiments show 
the advantage of model merging over the standard bigram
approach. The merged model assigns a lower perplexity to the test set
and uses considerably fewer states. 
