  The weirdest computer of all

  A quantum computer would rely on the surreal behaviour of the very small to
work miracles with information. There is new hope that it might someday be more
than fantasy

  THE computer has become so widespread, its applications so boundless, that it
is easy to forget that it is just a machine, constrained like everything else
by the laws of physics. But a machine is all it is, and a pretty simple one at
that. The underlying logic of the programs--the binary choices that control the
way a computer counts and calculates--would work just as well (if a lot more
slowly) in a device that shuttled ball-bearings instead of electrons.

  What, though, if a computer could be built around a different kind of
physics, the quantum physics that governs the weird and uncertain behaviour of
atoms and sub-atomic particles? A group of physicists and mathematicians that
is working on this question believes that quantum computing could change
computing just as thoroughly as quantum physics changed the Newtonian
certainties of classical physics earlier in the 20th century.

  Naturally, building a useful quantum computer would be difficult. Only the
very smallest objects behave in a detectably quantum way. This means that the
components of such a computer would be very tiny and very delicate. But so
great is the theoretical appeal of the machine that America's Defence Advanced
Research Projects Agency DARPA has just created an Institute for Quantum
Information and Computing, and given it $5m to investigate the possibilities.

  Bit players

  What makes quantum computing so attractive? For some jobs, a quantum computer
would be able to put even the best of today's supercomputers in the shade. It
would do this by employing a trick that ordinary computers cannot truly
master--parallel processing. Although supercomputers are fast, they can, like
all other digital computers, do only one thing at a time. Even the so called
"parallel" computers now available are just collections of machines that each
do only one thing at a time. But a quantum computer would be truly parallel. It
would be able to do many different things simultaneously in the same piece of
equipment.

  To see why, remember that every digital computer, no matter how wondrous its
applications, consists merely of a lot of switches that are linked together and
are either on or off. These switches can be thought of as the digits of
numbers, in which case their ons and offs are the ones and zeros of binary
counting. This is why, by a fortunate contraction of the words "binary digit",
the currency of data processing is known as the "bit".

  The switches inside a computer can also be interpreted as the trues and
falses of a form of logic known as Boolean algebra. Indeed, they are organised
into "logic gates" that do calculations using this algebra. A digital computer
is mainly a machine for altering bits by running them through logic gates. The
gate known as AND, for example, compares two bits. If both have a value of
"one", it creates an output of one; otherwise it creates a zero. With the next
tick of its internal clock, the computer then passes this output bit to another
gate for further processing. Each tick, then, corresponds to one step of the
calculation.

  In the quantum world, however, the rules are different. A quantum computer's
switches would not have to be either on or off. Like any quantum object which
can come in several distinct states, a quantum switch can carry on indefinitely
as a combination of all those states. It is not merely stuck halfway between on
and off; it is actually on and off simultaneously, as if it existed in two
parallel worlds.

  The bits in a "quantum computer" would not, therefore, be ones or zeros. They
would be quantum combinations of one and zero. Such vacillating pieces of
information are known as "qubits"(pronounced as "cubits", though they are
usually rather smaller than the ancient Hebrew unit of length).

  It is this simultaneous existence in many states that would give quantum
computing its power. An ordinary computer having (say) ten bits could exist in
only one of 1,024 states (all the ten-digit sequences that can be made from
ones and zeros) available to it, at each instant. A quantum computer with ten
qubits could exist in all 1,024 states at the same time. It could therefore
work on 1,024 calculations at once.

  But qubits are fiendishly hard to make. For a quantum switch to maintain its
multiple existence depends on one big proviso. Nothing can happen that might
disturb it. No light must shine on it, no stray air molecules may bump into it,
no inquiring probe can intrude on it. If it is disturbed, it stops vacillating
and chooses a definite state to be in. This choice depends on chance and on the
way its multiple personalities have interacted until then. If it happens
prematurely, the computation will be ruined.

  This proviso has made technical progress agonisingly slow. Paul Benioff, at
Argonne National Laboratory, in Illinois, first applied quantum theory to
computers in 1981. David Deutsch, at Oxford University, proposed the
possibility of quantum parallel computers in 1985. Yet both had to wait until
last year for the first two qubits to come on-line.

  One group of quantum mechanics who created them was led by Chris Monroe, who
works at the National Institute of Standards and Technology, in Boulder,
Colorado. Dr Monroe's group trapped a single ion (an atom with missing
electrons) of beryllium, by walling it in with electric and magnetic fields and
cooling it to within an ace of absolute zero (-273C). Such an ion has two
energy levels--providing the first qubit. And it can vibrate in two ways within
the trap--the second qubit. These qubits are linked together via a pulse of
laser light, which can switch the ion from one energy level to the other.
Whether it does so or not depends on which of the two vibrational patterns the
ion is in.

  The result is a logic gate called XOR. This has two input bits, and reverses
the value of the second if the first is "one". That is an important step.
Though using many types of gate makes designing ordinary computers easier, it
is possible to make do with just three: AND, NOT and COPY. A quantum computer
is even simpler. It requires only two sorts of gate, and XOR is one of them.
(The other would be able to change a zero into an arbitrary combination of zero
and one. This has no equivalent in conventional computing.)

  Qubits can also be made out of light, because light can be polarised in two
perpendicular directions. Jeff Kimble, a physicist at the California Institute
of Technology (Caltech), in Pasadena, and the head of the DARPA
quantum-computing institute, is working towards a light-based device. He and
his team have designed a piece of apparatus that allows photons (the particles
of which light is composed) to interact while they fly through a stream of
caesium atoms. This interaction could in principle form the basis of logic
gates like XOR.

  Trapping ions, though, may ultimately prove to be the best way to make real
quantum computers. Such devices would require thousands of ions, vibrating in
synchrony, and are certainly still in the realms of science fiction. But ion
traps housing up to six ions have already been built during other
atomic-physics projects. Groups at the Los Alamos National Laboratory, in New
Mexico, and the University of Innsbruck, in Austria, are trying to improve upon
them to connect a handful of qubits together.

  Qubits v true bits

  Why bother? Why should DARPA, better known for researching missile defences
and commissioning the precursor of the Internet, dabble in quantum theory?
Perhaps to make better calculators. There are already three mathematical
challenges known in which quantum computers would beat the pants off the
ordinary kind.

  The first is up DARPA's alley: cracking secret codes. The security of most
"public key" coding schemes, in which people can exchange secrets without
advance planning, relies on inscrutable large numbers. It is hard to
factorise--to find numbers that multiply together to produce--some 200 digit
numbers. But it is these factors that unlock the code. Since the programs for
finding them are excruciatingly tedious, even for a fleet of supercomputers,
such codes are pretty safe.

  A quantum computer, on the other hand, would make short work of this task. In
1994, Peter Shor, a mathematician at AT&T Labs, in Murray Hill, New Jersey,
designed a quantum circuit that could achieve it in many fewer steps. His
quantum software arranges the multiple personalities of the qubits in a way
that enables them to attack the problem separately, and then conspire together
so that when they are, in the end, forced to behave like normal bits, they will
be likely to produce the correct answer.

  Like much of quantum theory, this can be properly explained only in
mathematics, not words. But a sense of what it entails can be gained by
recognising that the equations of quantum theory are not unlike those of wave
motion, as Seth Lloyd, of the Massachusetts Institute of Technology, has
suggested. Each parallel path of a qubit is analogous to a sound wave of a
particular pitch. When different tones play together, they interfere,
reinforcing or cancelling one another depending on their strengths and timing.
The parallel lives of qubits do the same. And the strongest tones are the ones
likeliest to be chosen by the qubits when they are measured.

  In this analogy, an ordinary computation can be thought of as a melody of
single notes plinked out on a piano. A quantum computation, with its complex
array of chords and rhythms, sounds more like the Berlin Philharmonic. Dr
Shor's trick was to arrange the concert hall so that the music was completely
dominated by the proper overtones and beats--the rich timbre of the French
horns, say--that correspond to the correct solution.

  Lov Grover, a computer scientist at Bell Labs (which recently split from AT&T
Labs), has written quantum symphonies to solve two other problems. One,
published in May, is a way to search unsorted databases. If you were to sift
through 10,000 pieces of paper scattered about your desk in search of one
important memo, you would have to be prepared to scan 5,000 of them to have an
even chance of finding it. By assigning each parallel computation to pursue a
different choice, a quantum computer could do the same in only 40 runs.

  Dr Grover's other discovery, announced this month, is that quantum computers
would be talented statisticians. They would excel at finding single numbers
which depend collectively on lots of data: the median age of a large
population, for example. If a quantum computer and an ordinary computer with
the same internal clock rate raced to do it, the quantum computer would win
hands down.

  Back to the future

  There is, however, a snag. Qubits, not being true bits, are not truly
digital. One of the big advantages of recording and processing information
digitally is that it is difficult to make a mistake (electronic "ones" are not
that easily turned into "zeros"), and surprisingly easy to design ways to
recognise and correct any mistake that is made.

  This ease of correction was shown in the 1940s, at a time when the first
digital computers were being constructed. Claude Shannon, who also worked at
AT&T, set the ball rolling by investigating ways of encoding bits of
information so that they would resist errors during transmission down telephone
lines. In the 1950s, John von Neumann, one of the mathematicians who helped to
develop the theory of these early computers, went on to show how a reliable
computer could be built out of unreliable parts, by using Shannon's ideas and
combining them with extra (so-called redundant) circuitry.

  The simplest error-correcting code is triple-redundant. Each bit is copied
into two more bits: 0 becomes 000, and 1 becomes 111. If one bit accidentally
flips, the other two indicate this and can be used to fix it. But Rolf
Landauer, a physicist at the IBM Watson Research Centre, in Yorktown Heights,
New York, has insisted that this cannot work with qubits, which cannot be
measured, let alone copied. Yet error-correction would be vastly more important
in a quantum computer than an ordinary computer, since the disturbance of even
one qubit could ruin the coherence of the whole computation. If quantum
computing is to become more than a dream, it needs a new way to correct errors
as well as new hardware.

  It was therefore a welcome surprise when Dr Shor announced a year ago that he
had invented a quantum error-correcting code. Instead of three qubits, Dr
Shor's encoding formula required nine. A few months later other researchers at
IBM, Los Alamos and Oxford came up with codes that work with five of them.

  The idea begins with the qubit that needs to be protected from errors, and
four other qubits, set to zero. A sequence of logic gates changes and tangles
all five bits into a larger quantum combination. Just as one qubit is a mix of
two different states, two qubits are a mix of four, three are a mix of eight,
and so on. Five entangled qubits span 32 possibilities--each of the five-digit
sequences that can be made of ones and zeros.

  Five qubits are enough, though, to preserve the quantum ambiguity of what is
going on, even if one of them goes bad. One qubit being unmasked by, for
example, a collision with a stray air molecule, does not reveal enough
information for an observer to work anything out about the qubit originally
used to make the mixture. In these circumstances, the calculation can be
corrected, and proceed unhindered. The original mixing, in other words, creates
quantum cannon fodder for such interactions as would otherwise spoil a
combination. Some losses become tolerable without the game being given away.

  There are still problems to be overcome, of course. It is necessary to design
logic gates that will work on entangled bundles of five qubits at a time. And
errors can still creep in during the encoding process itself. Dr Shor's latest
achievements, to be announced at the Symposium on the Foundations of Computer
Science, being held in Burlington, Vermont, in October, address both of these
concerns. First, he has designed logic gates for protected qubits by combining
lots of two-qubit logic gates. Second, he has shown, theoretically, that the
improvements in components needed to make quantum computing reliable should
not, once such components actually exist, be too onerous.

  His second result is analogous to the ideas in one of von Neumann's
achievements, the "Synthesis of Reliable Organisms from Unreliable Parts".
Early sceptics of computing thought that allowing computers to work, say, ten
times longer on a problem would require components that were ten times as
reliable. Von Neumann showed that, with the shrewd use of error correcting
codes and redundant logic gates, the components did not need to be any more
reliable. All that was necessary was that the speed of the calculation be
slowed down to allow for error-correction. Dr Shor's result is not quite as
powerful as this. He has shown that to allow a quantum computation to proceed
for ten times as long, the reliability of components does have to be improved a
little. But the improvement required is a small fixed increment, not a factor
of ten.

  That quantum error-correction is possible at all has led to a new wave of
optimism about quantum computing. The circuitry for error-correction is too
complex to be built in a laboratory anytime soon. But the group from Innsbruck,
which is led by Peter Zoller and Rainer Blatt, has just published another
partial error-correcting code based on the principle of quantum cannon fodder.
This one is still simpler than Dr Shor's and should be particularly effective
in correcting the sort of errors that might be expected in an ion-trap quantum
computer.

  Three times five, silly

  The Innsbruck group hopes to try out its scheme with a three-bit computer by
1998. Meanwhile, in Los Alamos, Richard Hughes and his team are planning to
implement Dr Shor's algorithm for factorisation. With luck they will be able to
factorise the number 15 within five years.

  That this is considered ambitious hints at the difficulty of this latest
merger of physics and computing. Indeed, many physicists doubt whether quantum
computing will ever amount to anything useful. Dr Landauer is one of them. His
work on the ordinary (not quantum) physics of information led to a new
appreciation of information's inextricable relationship with physics. But he
does not expect IBM to be mass-producing quantum computers anytime soon.

  In this, he is assuredly correct. And even among the quantum computer's
enthusiasts, most researchers are motivated less by a desire to produce a
practical quantum computer than by a wish to learn how to wield more control
over quantum effects themselves. Until now, nobody has been able to direct
quantum states with the flexibility or precision required for quantum
computers. Doing so should help to illuminate some of quantum theory's more
curious features.

  In addition, if quantum computing really could be made to work, physicists
would have a powerful new analytical tool. One use for it would be to explore
the many ramifications of quantum theory (such as the "Hubbard model" of how
electrons hop around in a crystal, or theories of fundamental particles) that
are thought to be correct but cannot be tested precisely. The sort of equations
needed to check these ideas are too much for even the most nimble non-quantum
supercomputer to handle.

  In 1982, the late Richard Feynman, who was also at Caltech, suggested that a
quantum computer would help to solve these sorts of problems. To simulate an
ordinary object, only a few numbers are needed. For a quantum object every
possible state must be tracked--an enormous set of numbers. How better to keep
up with the calculation than by using something that is itself in a multitude
of states?

  Whether such uses will come to fruition remains to be seen. But, as Dr
Landauer points out, in one sense quantum computing has already been useful. It
has provided a salutary reminder that computing does not take place in an
abstract mathematical world. It uses earth, air, fire and water--or single
atoms of those things. It is subject to all the limitations, and all the
possibilities, written in the laws of physics. Some mathematicians and computer
scientists spend their days searching for the quickest possible algorithm to
solve particular problems. To their surprise they must now learn quantum
theory, in order to cover all the possibilities allowed by nature. After a long
absence, they are being forced to return from the virtual reality of
information science and deal with the real world, in all its indeterminate
queerness.
